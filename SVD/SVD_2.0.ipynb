{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b8442a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:170% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{640404923: ['burger', 'fatty'], 640405058: ['burger', 'healthy', 'vegan'], 640405347: ['sides', 'fatty'], 640405331: ['sides', 'fatty'], 640405380: ['sides', 'cold-drink'], 640405395: ['sides', 'cold-drink', 'dessert'], 640405348: ['sides', 'healthy', 'vegan', 'hot-drink']}\n",
      "{'burger': [640404923, 640405058], 'sides': [640405347, 640405331, 640405380, 640405395, 640405348], 'fatty': [640404923, 640405347, 640405331], 'healthy': [640405058, 640405348], 'vegan': [640405058, 640405348], 'cold-drink': [640405380, 640405395], 'hot-drink': [640405348], 'dessert': [640405395]}\n",
      "      item_id                       name taste_profile      type\n",
      "0   640404923                  Hamburger        savory    burger\n",
      "1   640404963               Cheeseburger        savory    burger\n",
      "2   640405025         Bacon Cheeseburger        savory    burger\n",
      "3   640405058              Veggie Burger        savory    burger\n",
      "4   640405621        Veggie Cheeseburger        savory    burger\n",
      "5   640405085           Double Hamburger        savory    burger\n",
      "6   640405112        Double Cheeseburger        savory    burger\n",
      "7   640405172  Double Bacon Cheeseburger        savory    burger\n",
      "8   640405355                Small Drink      chilling  beverage\n",
      "9   640405371              Regular Drink      chilling  beverage\n",
      "10  640405380                Large Drink      chilling  beverage\n",
      "11  640405389                Small Shake         sweet  beverage\n",
      "12  640405395              Regular Shake         sweet  beverage\n",
      "13  640405399                Large Shake         sweet  beverage\n",
      "14  640405296                Small Fries        savory      side\n",
      "15  640405307              Regular Fries        savory      side\n",
      "16  640405315                Large Fries        savory      side\n",
      "17  640405323          Small Curly Fries        savory      side\n",
      "18  640405331        Regular Curly Fries        savory      side\n",
      "19  640405339          Large Curly Fries        savory      side\n",
      "20  640405347                Onion Rings         sweet      side\n",
      "21  640405348                     Coffee        bitter  beverage\n",
      "['burger', 'sides', 'fatty', 'healthy', 'vegan', 'cold-drink', 'hot-drink', 'dessert']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "# change the cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:170% !important; }</style>\"))\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 10000)\n",
    "\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow as tf\n",
    "#load data from data files and place into panda dataframes\n",
    "#custOrders = pd.read_csv('../FeatureEngineering/data/customer_orders.csv', low_memory=False)\n",
    "\n",
    "gist_url = \"https://gist.githubusercontent.com/GottaGitGoing/c01194dc318f3a31a07d1ae68d31b163/raw/ec37b65f0aa79cf89480981cd9be0df6399dfafb/customer_orders.csv\"\n",
    "custOrders = pd.read_csv(gist_url,low_memory=False)\n",
    "itemID=pd.read_csv('../SQL/item.csv')\n",
    "tagLists=pd.read_csv('../SQL/tags.csv')\n",
    "\n",
    "item_to_tag={} #maps items to tags associated with them\n",
    "tag_to_item={} #maps tags to the items that have them\n",
    "ti={}\n",
    "for index, row in tagLists.iterrows():\n",
    "    #print(row['item_id'], row['tagName'])\n",
    "    if row['tagID'] not in ti:\n",
    "        ti[row['tagID']]=row['tagName']\n",
    "    \n",
    "    #create dictionary with key=itemID, value=list of tags that the item has\n",
    "    if row['item_id'] not in item_to_tag:\n",
    "        item_to_tag[row['item_id']]=[row['tagName']]\n",
    "    else:\n",
    "        item_to_tag[row['item_id']].append(row['tagName'])\n",
    "        \n",
    "    #create dictionary with key=tag, value=list of item ID's that have the key-tag\n",
    "    if row['tagName'] not in tag_to_item:\n",
    "        tag_to_item[row['tagName']]=[row['item_id']]\n",
    "    else:\n",
    "        tag_to_item[row['tagName']].append(row['item_id'])\n",
    "\n",
    "print(item_to_tag)\n",
    "print(tag_to_item)\n",
    "print(itemID)\n",
    "#turn off panda max column display limit\n",
    "pd.options.display.max_columns\n",
    "mns = None\n",
    "\n",
    "\n",
    "\n",
    "#array holding the tag names in the order they will be in preferences\n",
    "tagName=['']*len(ti)\n",
    "for k in ti.keys():\n",
    "    tagName[k]=ti[k]\n",
    "#tagNames=['burger', 'sides', 'fatty', 'healthy', 'vegan', 'cold-drink', 'hot-drink', 'dessert']\n",
    "\n",
    "#\n",
    "preferences={}\n",
    "#burger, sides, fatty, healthy, vegan, cold-drink, hot-drink, dessert\n",
    "preferences[52]=[10.0,10.0,10.0,10.0, 0, 10.0,10.0,10.0]\n",
    "preferences[194]=[1.5,0,1.8,0, 1 ,0,0,0]\n",
    "preferences[1]=[0,0,0,0, 1 ,0,0,0]\n",
    "print(tagName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43911915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def makeDF(rows, cols):\n",
    "    a= np.zeros((rows,cols))    \n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "#https://towardsdatascience.com/beginners-guide-to-creating-an-svd-recommender-system-1fd7326d1f65\n",
    "\n",
    "#=====SVD Functions=====\n",
    "def svd(train, k):\n",
    "    \n",
    "    utilMat = np.array(train)\n",
    "    \n",
    "    \n",
    "    # the nan or unavailable entries are masked\n",
    "    mask = np.isnan(utilMat)\n",
    "    masked_arr = np.ma.masked_array(utilMat, mask)\n",
    "    item_means = np.mean(masked_arr, axis=0)\n",
    "    # nan entries will replaced by the average rating for each item\n",
    "    utilMat = masked_arr.filled(item_means)\n",
    "    x = np.tile(item_means, (utilMat.shape[0],1))\n",
    "    # we remove the per item average from all entries.\n",
    "    # the above mentioned nan entries will be essentially zero now\n",
    "    utilMat = utilMat - x\n",
    "    \n",
    "    \n",
    "\n",
    "    # The magic happens here. U and V are user and item features\n",
    "    U, s, V=np.linalg.svd(utilMat, full_matrices=False)\n",
    "    s=np.diag(s)\n",
    "    # we take only the k most significant features\n",
    "    s=s[0:k,0:k]\n",
    "    U=U[:,0:k]\n",
    "    V=V[0:k,:]\n",
    "    s_root=sqrtm(s)\n",
    "    Usk=np.dot(U,s_root)\n",
    "    skV=np.dot(s_root,V)\n",
    "    UsV = np.dot(Usk, skV)\n",
    "    UsV = UsV + x\n",
    "    print(\"svd done\")\n",
    "    return UsV\n",
    "\n",
    "#=========\n",
    "\n",
    "#not used at the moment\n",
    "def rmse(true, pred):\n",
    "    # this will be used towards the end\n",
    "    x = true - pred\n",
    "    return sum([xi*xi for xi in x])/len(x)\n",
    "\n",
    "#======\n",
    "\n",
    "def getPrefArr(user):\n",
    "    #function gets a userID and returns an array of size(#ofitems on menu)\n",
    "    #will check each item's tags, then sum the preference-tags score associated with eachitem and return them\n",
    "    #as an array\n",
    "    #if no user preferneces, can send back all zeores\n",
    "    if user not in preferences:\n",
    "        return np.zeros(len(itemID_Dict))\n",
    "    \n",
    "    p=preferences[user]\n",
    "    #make ratings array with score for each item on the menu\n",
    "    ret=np.zeros(len(itemID_Dict))\n",
    "    #iterate through the tags, using tag_to_item dictionary to find itemID's with each tag, using itemList to find the index in ret which \n",
    "    # is associated with the itemID, then adding the tag's preference value to that index\n",
    "    for index, val in enumerate(tagName):\n",
    "        arr=tag_to_item[val]\n",
    "        for i in arr:\n",
    "            ret[itemList.index(i)]+=p[index]  \n",
    "    \n",
    "    return ret\n",
    "\n",
    "#===============\n",
    "\n",
    "def predict(targetUser):\n",
    "    #function will return a sorted rankings of menu item using the targetUser order history and prferences (userItem_matrix_df_with_means)\n",
    "    #if user has no preferences or order history, function will append this user to the userItem_matrix\n",
    "    global userItem_matrix, userItem_matrix_df_with_means, user_to_row, itemID_Dict, preferences, tagName, binaryTags\n",
    "    #check if user is already in dataframe, if not then add to all appropriate data structures\n",
    "    if(targetUser not in user_to_row):\n",
    "        userItem_matrix=np.append(userItem_matrix, [getPrefArr(targetUser)] , axis=0)        \n",
    "        user_to_row[targetUser]=userItem_matrix.shape[0]-1\n",
    "        update_UserItem_dataframe()\n",
    "        print(\"added new user\")\n",
    "    \n",
    "    #call svd function and get predictions\n",
    "    numOfFeatures=20\n",
    "    FullOutput=(svd(userItem_matrix_df_with_means, numOfFeatures) )\n",
    "    output=FullOutput[user_to_row[targetUser]]\n",
    "    ranking=[]\n",
    "    #link all ratings to their item ID's\n",
    "    for index, val in enumerate((list(userItem_matrix_df_with_means))):\n",
    "        ranking.append((val, output[index]))\n",
    "        \n",
    "    #get a new rankings list which has itemID and the scores predicted for it \n",
    "    sorted_ranking=[]\n",
    "    for index, val in enumerate(ranking):\n",
    "        sorted_ranking.append(( ( val[0], itemID_Dict[val[0]] )  , val[1]))\n",
    "\n",
    "    #sort list by the score of each item\n",
    "    sorted_ranking = sorted(sorted_ranking, key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    #check if user has a preference in one of the binary tags, if it does then we will remove all items which do not have that tag\n",
    "    if targetUser not in preferences:\n",
    "        p=np.zeros(len(itemID_Dict))\n",
    "    else:\n",
    "        p=preferences[targetUser]\n",
    "\n",
    "    return sorted_ranking\n",
    "\n",
    "\n",
    "\n",
    "def update_UserItem_dataframe():\n",
    "    #function commit any changes made in the userItem_matrix to the User-item dataframe(userItem_matrix_df), \n",
    "    #then makes a copy and replace all zeroes in the matrix the with mean value of the column(userItem_matrix_df_with_means)\n",
    "    #use of global keywork allow the changes in the function to be applied to the entire \n",
    "    global userItem_matrix, userItem_matrix_df, itemList, userItem_matrix_df_with_means\n",
    "    userItem_matrix_df=pd.DataFrame(userItem_matrix,columns=itemList)\n",
    "    data = userItem_matrix_df.copy()\n",
    "    m = data == 0\n",
    "    means = np.ma.array(data, mask = m).mean(0)\n",
    "    userItem_matrix_df_with_means=data + m * means.data\n",
    "\n",
    "def update_Preferences_from_Orders():\n",
    "    #wrapper function for taking all rows in orderData_matrix_noPref, updating the user preferences by transforming\n",
    "    #the item counts into tag values, see getTagsArr() for details\n",
    "    #NOTE: Also does not erase any orders so calling this function multiple times will just update the user preferences with data that is already represented\n",
    "    global orderData_matrix_noPref, preferences, row_to_user, orderData_matrix_noPref_df\n",
    "    #using orderData_matrix_noPref update preference for each user\n",
    "    for index, row in orderData_matrix_noPref_df.iterrows():\n",
    "        update_User_Preference(row_to_user[index])\n",
    "\n",
    "\n",
    "def getTagsArr(itemArr_df):\n",
    "    #function takes as input a pd.series which contains x cells, where x is the number of items on the menu\n",
    "    #The function first initializes an array ret, which is of size y, where y is the number of tags that exist\n",
    "    #Function then iterates through the input and uses the item_to_tag mapping to find the tags each item is associated with,\n",
    "    #then adds some values to the ret array at the indexes which represent those particular tags\n",
    "    # ret array is returned as output\n",
    "    global tagName, item_to_tag\n",
    "    ret=[0]*len(tagName)\n",
    "    for itemID in itemArr_df.index:\n",
    "        if itemID in item_to_tag:\n",
    "           # print(str(cols)+\" : \"+str(item_to_tag[cols]))\n",
    "            for t in item_to_tag[itemID]:\n",
    "                ind=tagName.index(t)\n",
    "                ret[ind]+=itemArr_df.loc[itemID]\n",
    "    return(ret)\n",
    "\n",
    "def update_User_Preference(userID):\n",
    "    #function will take a userID, find the row associated with that user in the orderData_matrix_noPref_df matrix, and \n",
    "    # use getTagsArr to obtain a item-to-tag mapping\n",
    "    #then it will add or increment the user's preference scores and return\n",
    "    global orderData_matrix_noPref, preferences,user_to_row, row_to_user, orderData_matrix_noPref_df, tagName\n",
    "    #ret will the the array of values that the function returns, it will hold scores for each tag\n",
    "    #which come from the item-level order counts. It will use the getTagsArr to get these\n",
    "    #this function can then modify these values(if needed) before adding this\n",
    "    prefs=[0]*len(tagName)\n",
    "    if userID not in user_to_row:\n",
    "        return prefs\n",
    "    else:   \n",
    "        prefs=getTagsArr(orderData_matrix_noPref_df.iloc[user_to_row[userID]] )\n",
    "        #modify scores\n",
    "        prefs=pd.Series(prefs)*0.1\n",
    "        \n",
    "\n",
    "        #if user has existing preferences, add them to the new scores\n",
    "        if userID in preferences:\n",
    "            preExisting=preferences[userID]\n",
    "            prefs=preExisting+prefs\n",
    "            \n",
    "        #save prefs to the preferences dictionary, with userID as the key\n",
    "        #here I cast the preferences from a panda.Series to a python list, but it can remain as a Series if needed\n",
    "        preferences[userID]=list(prefs)\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ddf3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_Preferences_from_Orders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdea3d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------itemID_Dict------------\n",
      "{640404923: (0, 'Hamburger'), 640404963: (1, 'Cheeseburger'), 640405025: (2, 'Bacon Cheeseburger'), 640405058: (3, 'Veggie Burger'), 640405621: (4, 'Veggie Cheeseburger'), 640405085: (5, 'Double Hamburger'), 640405112: (6, 'Double Cheeseburger'), 640405172: (7, 'Double Bacon Cheeseburger'), 640405355: (8, 'Small Drink'), 640405371: (9, 'Regular Drink'), 640405380: (10, 'Large Drink'), 640405389: (11, 'Small Shake'), 640405395: (12, 'Regular Shake'), 640405399: (13, 'Large Shake'), 640405296: (14, 'Small Fries'), 640405307: (15, 'Regular Fries'), 640405315: (16, 'Large Fries'), 640405323: (17, 'Small Curly Fries'), 640405331: (18, 'Regular Curly Fries'), 640405339: (19, 'Large Curly Fries'), 640405347: (20, 'Onion Rings'), 640405348: (21, 'Coffee')}\n",
      "---------code_to_item---------\n",
      "{0: 'Hamburger', 1: 'Cheeseburger', 2: 'Bacon Cheeseburger', 3: 'Veggie Burger', 4: 'Veggie Cheeseburger', 5: 'Double Hamburger', 6: 'Double Cheeseburger', 7: 'Double Bacon Cheeseburger', 8: 'Small Drink', 9: 'Regular Drink', 10: 'Large Drink', 11: 'Small Shake', 12: 'Regular Shake', 13: 'Large Shake', 14: 'Small Fries', 15: 'Regular Fries', 16: 'Large Fries', 17: 'Small Curly Fries', 18: 'Regular Curly Fries', 19: 'Large Curly Fries', 20: 'Onion Rings', 21: 'Coffee'}\n",
      "------itemList--------\n",
      "[640404923, 640404963, 640405025, 640405058, 640405621, 640405085, 640405112, 640405172, 640405355, 640405371, 640405380, 640405389, 640405395, 640405399, 640405296, 640405307, 640405315, 640405323, 640405331, 640405339, 640405347, 640405348]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#transform itemID info which is from the csv, into an itemID_Dictionary which will holds an item's index in the menu and its name\n",
    "# will also create code_to_item, which is another mapping of the itemIndex to the itemName \n",
    "itemID['item_score'] = range(1, len(itemID) + 1)\n",
    "itemID = itemID.drop(\"item_description\", axis=1, errors='ignore')\n",
    "itemID = itemID.drop(\"item_image\", axis=1, errors='ignore')\n",
    "#creates dictionary where key is a menu's id number and the value is a \n",
    "#tuple with the new menu id embedding(for ML model to predict on) and the menu item's name\n",
    "itemID_Dict={}\n",
    "itemList=[]\n",
    "for i, row in itemID.iterrows():\n",
    "    itemID_Dict[row.loc[\"item_id\"]]=(row.loc[\"item_score\"]-1, row.loc[\"name\"])\n",
    "    itemList.append(row.loc[\"item_id\"])\n",
    "\n",
    "#save item_id to item name\n",
    "code_to_item={}\n",
    "for pair in itemID_Dict:\n",
    "    code_to_item[itemID_Dict[pair][0]]=itemID_Dict[pair][1]\n",
    "#print out dictionary and itemID dataframe\n",
    "print(\"-----------itemID_Dict------------\")\n",
    "print(itemID_Dict)\n",
    "print(\"---------code_to_item---------\")\n",
    "print(code_to_item)\n",
    "print(\"------itemList--------\")\n",
    "print(itemList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8712c63c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newUser_noPref' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14348/2086821563.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mnewUser\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mgetPrefArr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrentUser\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#np.zeros(len(itemID_Dict))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0morderData_matrix_noPref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morderData_matrix_noPref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnewUser_noPref\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mnewUser_noPref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemID_Dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'newUser_noPref' is not defined"
     ]
    }
   ],
   "source": [
    "#generate user-item matrix, and matrix which will populate itself with order data (but not preference data, that will be added later)\n",
    "\n",
    "#Will also save the user associated with each row in the user-item matrix, the userID is not stored within the \n",
    "#user-item matrix and must be saved sepereatly in a user->row dictionary mapping\n",
    "#We will also reverse the dictionary and create a row->user dictionary and save both mappings\n",
    "\n",
    "#initalize\n",
    "userItem_matrix=makeDF(0, len(itemID_Dict))\n",
    "orderData_matrix_noPref=makeDF(0, len(itemID_Dict))\n",
    "\n",
    "uniqueUserCount=0\n",
    "user_to_row={}\n",
    "\n",
    "#populate user-item matrix\n",
    "for i, row in custOrders.iterrows():\n",
    "    currentUser=row.loc[\"customer_id\"]\n",
    "    currentOrder=row.loc[\"order_id\"]\n",
    "    currentItemIndex=row.loc[\"item_id\"]\n",
    "    \n",
    "    if currentUser not in user_to_row:\n",
    "        user_to_row[currentUser]=uniqueUserCount\n",
    "        uniqueUserCount+=1\n",
    "        \n",
    "        #also need to add pre-existing preferences\n",
    "        newUser =  getPrefArr(currentUser) #np.zeros(len(itemID_Dict))\n",
    "        \n",
    "        orderData_matrix_noPref=np.append(orderData_matrix_noPref, [newUser_noPref] , axis=0)\n",
    "        \n",
    "        newUser_noPref = np.zeros(len(itemID_Dict))\n",
    "        userItem_matrix= np.append(userItem_matrix, [newUser] , axis=0)\n",
    "\n",
    "    #for each order on a menu item, increment a cell in the orderData_matrix_noPref and userItem_matrix\n",
    "    i=user_to_row[currentUser]\n",
    "    orderData_matrix_noPref[i, itemID_Dict[currentItemIndex][0]-1]+=1\n",
    "    userItem_matrix[i, itemID_Dict[currentItemIndex][0]-1]+=1\n",
    "\n",
    "\n",
    "#Will also create a row->user dictionary so we can save both mappings\n",
    "print(user_to_row)\n",
    "row_to_user = {value:key for key, value in user_to_row.items()}\n",
    "print(row_to_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe versions of orderData_matrix_noPref and userItem_matrix, with item IDs as the column indexes\n",
    "orderData_matrix_noPref_df=pd.DataFrame(orderData_matrix_noPref,columns=itemList)\n",
    "userItem_matrix_df=pd.DataFrame(userItem_matrix,columns=itemList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee906f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this segment randomly removed indexes in the userItem_matrix_df. These indexes and the true rating in them would\n",
    "#have acted like testing data and it would be possible to evaluate the predicted scores better\n",
    "#but due to time constraints I cannot implement this evalutation metric. As it is not necessary for the functionality of the\n",
    "#system I have commented out this section\n",
    "\n",
    "#temp = a copy of userItem_matrix_df which would have some of its scores randomly removed and placed in testingData dictionary\n",
    "'''\n",
    "temp=userItem_matrix_df.copy()\n",
    "\n",
    "randomIndices = np.random.choice(np.arange(temp.size), replace=False,size=int(temp.size * 0.2))\n",
    "testingData={}\n",
    "for val in (randomIndices):\n",
    "#    print(str(val)+\" = [\"+str(val//len(itemID_Dict))+\"]\"+ \"[ \"+str(val%len(itemID_Dict))+\"]\" )\n",
    "    row=val//len(itemID_Dict)\n",
    "    col=val%len(itemID_Dict)\n",
    "    testingData[val]=temp.iloc[row,col]\n",
    "    temp.iloc[row,col]=0\n",
    "    \n",
    "print(temp)\n",
    "'''\n",
    "\n",
    "#print(testingData)\n",
    "# for val in (randomIndices):\n",
    "#     print(str(val)+\" = [\"+str(val//len(itemID_Dict))+\"]\"+ \"[ \"+str(val%len(itemID_Dict))+\"]\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb9dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://stackoverflow.com/questions/60169809/replace-zeros-with-mean-of-non-zeros-along-an-axis-of-array-python-numpy\n",
    "#this segment replaces the zeroes in the temp dataframe(a copy of the user-item matrix) with the average of the column score\n",
    "#this non-zerofilled array is temp2\n",
    "\n",
    "#data=temp #if random values were removed, use this line and comment out next line\n",
    "data = userItem_matrix_df.copy()\n",
    "m = data == 0\n",
    "means = np.ma.array(data, mask = m).mean(0)\n",
    "userItem_matrix_df_with_means=data + m * means.data\n",
    "\n",
    "print(userItem_matrix_df_with_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834bfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "userID_to_predict_on=52\n",
    "predict(userID_to_predict_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6962ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preferences before\n",
    "print(preferences)\n",
    "update_Preferences_from_Orders()\n",
    "print(\"===========\")\n",
    "#preferences after\n",
    "print(preferences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
